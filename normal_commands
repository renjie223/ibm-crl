!#/bin/sh

CRL : 172.16.1.16 opuser xcvsdf234           --vpn
Longsys : 172.16.1.176 opuser xcvsdf234
bigant : 9.186.107.15 yarn hadoop2.4

//完整的RTA环境
	172.16.3.99

172.16.1.16   crl-001
---------17   crl-002
--
172.16.1.25   crl-010

9.186.107.15	bigant-test-001  yarn hadoop2.4    

postMan
chrome
VPNC
git
gradle
mvn 

//=============================================
ssh-keygen
cat .ssh/id_rsa.pub
scp firephoenix@9.181.61.77:/home/firephoenix/sshkey.txt ./
cd /etc/vpnc
sudo vpnc ibmvpnc.conf	
sudo vpnc-disconnect

git clone git@github.rtp.raleigh.ibm.com:qiuyj-cn/RTA-components.git

ps -ef | grep vpnc

git checkout stable
git status
git pull origin stable
git push origin gitlab_master
git merge stable
git checkout gitlab_master
git log
git reset --hard e4fbd62b32e864c650d55fbd9215fefec5de39bb

gradle build publishToMavenLocal
gradle build

mvn package
mvn clean package

mpstat -P ALL
mpstat
sudo apt-get install indicator-multiload

//Atom:
    ctrl+shift+M   Preview
    ctrl+,	View Project

ps -ef | grep vpnc

//Kafka：
vi ~/.bashrc 
cd $KAFKA_HOME
ssh yarn@bigant-test-001
$KAFKA_HOME=/sdh/install/kafka_2.10_0.9.0.0/instance_1

ssh opuser@rta-008

/opt/kafka kafka安装路径 kube-debug节点上kafka的路径

使用Kafka的一些步骤：

Step 2: Start the server
    > bin/zookeeper-server-start.sh config/zookeeper.properties
    > bin/kafka-server-start.sh config/server.properties
Step 3: Create a topic
    > bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
    > bin/kafka-topics.sh --list --zookeeper localhost:2181
Step 4: Send some messages
    > bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
Step 5: Start a consumer
    > bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test	from-beginning
Step 6: Setting up a multi-broker cluster
    > cp config/server.properties config/server-1.properties
    > cp config/server.properties config/server-2.properties	
    > bin/kafka-server-start.sh config/server-1.properties &
    > bin/kafka-server-start.sh config/server-2.properties &
    > bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic
    > bin/kafka-topics.sh  --zookeeper localhost:2181 --topic my-replicated-topic
    
bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic testTopic


ssh-copy-id -i ~/.ssh/id_rsa.pub yarn@bigant-test-004   //设置无密码登陆



ssh opuser@crl-008     
ssh cdsdep@172.16.1.27   cubernets   /usr/local/bin
ssh yarn@bigant-test-001   echo yarn-clustr等等

ps -ef | grep vpnc



//部署过程，杀掉相关进程部分指令
ps -ef | grep tomcat |awk '{print $2}'
kill -9 $(ps -ef | grep tomcat |awk '{print $2}')


//Gluster相关指令
1. gluster peer status
2. /data分区
3. gluster volume info
   gluster volume start gv1
   mount.gluster gluster:gv1 /mnt   实现挂在，一个目录只能挂在一个


//Docker相关指令
1. 更新镜像
  修改Dockerfile，执行sudo docker build -t"标签" .  (.标示Dockerfile在当前路径下)

//Tmux
cmd=Tmux
$cmd has -t $session
$cmd new-session -d -s $session  //语句是阻塞的，所以要加-d 后台运行
$cmd selectp -t $session  //选择操作的session
$cmd split-window -h
window=${session}:0   //选择窗口
  pane=${window}.0   //选择pane
  path=/home/yarn/longsys_debug/kafka
  $cmd send-keys -t "$pane" "./produce.sh ${TOPICNAME}" Enter  //执行相应脚本
  $cmd select-pane -t "$pane"
  pane1=${window}.1
  $cmd send-keys -t "$pane1" "./consume.sh ${TOPICNAME}" Enter
  $cmd select-pane -t "$pane"
  $cmd select-window -t "$window"



